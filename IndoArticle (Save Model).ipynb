{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12534674,"sourceType":"datasetVersion","datasetId":7913061}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install rouge_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T07:12:22.437156Z","iopub.execute_input":"2025-07-24T07:12:22.437403Z","iopub.status.idle":"2025-07-24T07:12:28.196771Z","shell.execute_reply.started":"2025-07-24T07:12:22.437383Z","shell.execute_reply":"2025-07-24T07:12:28.195878Z"}},"outputs":[{"name":"stdout","text":"Collecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.2.1)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.1)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rouge_score) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rouge_score) (2024.2.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=89002e4d2348b2842ee1b8721f5ef896a2b02a5fbc30408268029a24bd82574c\n  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud\nimport os\nimport torch\nfrom datasets import Dataset, DatasetDict\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSeq2SeqLM,\n    DataCollatorForSeq2Seq,\n    Seq2SeqTrainingArguments,\n    Seq2SeqTrainer,\n    EarlyStoppingCallback\n)\nfrom sklearn.model_selection import train_test_split\nimport re\nfrom rouge_score import rouge_scorer\nimport warnings\n\nwarnings.filterwarnings('ignore')\nnp.random.seed(42)\ntorch.manual_seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T07:12:28.198316Z","iopub.execute_input":"2025-07-24T07:12:28.198652Z","iopub.status.idle":"2025-07-24T07:12:55.015070Z","shell.execute_reply.started":"2025-07-24T07:12:28.198618Z","shell.execute_reply":"2025-07-24T07:12:55.014422Z"}},"outputs":[{"name":"stderr","text":"2025-07-24 07:12:37.930738: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753341158.092118      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753341158.139995      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7d931ddb8db0>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"FILE_PATH = '/kaggle/input/indo-article-data-summarization/IndoData200.csv'\nBEST_MODEL = \"gaduhhartawan/indobart-base\"\nSAVE_MODEL_PATH = \"./saved_indobart_model\"\nMAX_INPUT_LENGTH = 512\nMAX_TARGET_LENGTH = 128\nTRAIN_BATCH_SIZE = 4\nEVAL_BATCH_SIZE = 4\nNUM_TRAIN_EPOCHS = 4\nRANDOM_STATE = 42\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\n# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T07:12:55.016110Z","iopub.execute_input":"2025-07-24T07:12:55.016777Z","iopub.status.idle":"2025-07-24T07:12:55.021309Z","shell.execute_reply.started":"2025-07-24T07:12:55.016756Z","shell.execute_reply":"2025-07-24T07:12:55.020627Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Load data\ndf = pd.read_csv(FILE_PATH)\nprint(f\"Dataset loaded with {len(df)} samples\")\n\n# Create train/validation/test splits\ntrain_df, temp_df = train_test_split(df, test_size=0.2, random_state=RANDOM_STATE)\nval_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=RANDOM_STATE)\n\nprint(f\"Train set: {len(train_df)} samples\")\nprint(f\"Validation set: {len(val_df)} samples\")\nprint(f\"Test set: {len(test_df)} samples\")\n\n# Create HuggingFace datasets\ntrain_dataset = Dataset.from_pandas(train_df[['article', 'summary']].reset_index(drop=True))\nval_dataset = Dataset.from_pandas(val_df[['article', 'summary']].reset_index(drop=True))\ntest_dataset = Dataset.from_pandas(test_df[['article', 'summary']].reset_index(drop=True))\n\ndataset_dict = DatasetDict({\n    'train': train_dataset,\n    'validation': val_dataset,\n    'test': test_dataset\n})\n\ndef preprocess_function(examples, tokenizer, max_input_length, max_target_length):\n    inputs = tokenizer(\n        examples['article'],\n        max_length=max_input_length,\n        truncation=True,\n        padding=False\n    )\n\n    with tokenizer.as_target_tokenizer():\n        targets = tokenizer(\n            examples['summary'],\n            max_length=max_target_length,\n            truncation=True,\n            padding=False\n        )\n\n    inputs['labels'] = targets['input_ids']\n    return inputs\n\n# ROUGE metrics computation\ndef compute_rouge_metrics(predictions, references):\n    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n    rouge1_scores, rouge2_scores, rougeL_scores = [], [], []\n\n    for pred, ref in zip(predictions, references):\n        pred = str(pred).strip() if pred else \" \"\n        ref = str(ref).strip() if ref else \" \"\n        scores = scorer.score(ref, pred)\n        rouge1_scores.append(scores['rouge1'].fmeasure)\n        rouge2_scores.append(scores['rouge2'].fmeasure)\n        rougeL_scores.append(scores['rougeL'].fmeasure)\n\n    return {\n        'rouge1': np.mean(rouge1_scores),\n        'rouge2': np.mean(rouge2_scores),\n        'rougeL': np.mean(rougeL_scores)\n    }\n\n# Compute metrics function for trainer\ndef compute_metrics(eval_preds, tokenizer):\n    predictions, labels = eval_preds\n\n    if isinstance(predictions, tuple):\n        predictions = predictions[0]\n    \n    predictions = np.where(predictions != -100, predictions, tokenizer.pad_token_id)\n    vocab_size = len(tokenizer)\n    predictions = np.clip(predictions, 0, vocab_size - 1)\n\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    decoded_preds = [pred.strip() for pred in decoded_preds]\n    decoded_labels = [label.strip() for label in decoded_labels]\n    \n    rouge_metrics = compute_rouge_metrics(decoded_preds, decoded_labels)\n    return rouge_metrics\n\ndef train_and_save_model(model_name, dataset_dict, save_path):\n    print(f\"\\n{'='*60}\\nTraining and Saving Model: {model_name}\\n{'='*60}\")\n\n    # Load tokenizer and model\n    tokenizer = AutoTokenizer.from_pretrained(model_name, legacy=False)\n    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n\n    # Handle vocab size mismatch\n    if model.config.vocab_size != len(tokenizer):\n        print(f\"Alert: Vocab size mismatch found for {model_name}.\")\n        print(f\"  - Model config vocab size: {model.config.vocab_size}\")\n        print(f\"  - Tokenizer vocab size:    {len(tokenizer)}\")\n        print(\"Resizing model token embeddings to match tokenizer.\")\n        model.resize_token_embeddings(len(tokenizer))\n        \n    if tokenizer.pad_token is None:\n        tokenizer.pad_token = tokenizer.eos_token\n        model.config.pad_token_id = tokenizer.pad_token_id\n\n    model.to(device)\n\n    # Tokenize datasets\n    tokenized_datasets = dataset_dict.map(\n        lambda examples: preprocess_function(examples, tokenizer, MAX_INPUT_LENGTH, MAX_TARGET_LENGTH),\n        batched=True,\n        remove_columns=dataset_dict['train'].column_names\n    )\n\n    data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, padding=True)\n\n    # Training arguments\n    training_args = Seq2SeqTrainingArguments(\n        output_dir='./results_training',\n        logging_dir='./logs_training',\n        num_train_epochs=NUM_TRAIN_EPOCHS,\n        per_device_train_batch_size=TRAIN_BATCH_SIZE,\n        per_device_eval_batch_size=EVAL_BATCH_SIZE,\n        warmup_steps=0,\n        weight_decay=0,\n        logging_strategy=\"epoch\",\n        eval_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        load_best_model_at_end=True,\n        metric_for_best_model=\"rougeL\",\n        greater_is_better=True,\n        save_total_limit=1,\n        predict_with_generate=True,\n        generation_max_length=MAX_TARGET_LENGTH,\n        generation_num_beams=2,\n        fp16=torch.cuda.is_available(),\n        report_to=\"none\",\n    )\n\n    # Initialize trainer\n    trainer = Seq2SeqTrainer(\n        model=model,\n        args=training_args,\n        train_dataset=tokenized_datasets['train'],\n        eval_dataset=tokenized_datasets['validation'],\n        tokenizer=tokenizer,\n        data_collator=data_collator,\n        compute_metrics=lambda eval_preds: compute_metrics(eval_preds, tokenizer),\n        callbacks=[EarlyStoppingCallback(early_stopping_patience=2, early_stopping_threshold=0.0)]\n    )\n\n    print(\"--- Starting training ---\")\n    trainer.train()\n\n    print(\"\\n--- Evaluating on test set ---\")\n    test_results = trainer.evaluate(eval_dataset=tokenized_datasets['test'], metric_key_prefix=\"test\")\n\n    print(f\"\\nFinal Test Results for {model_name}:\")\n    print(f\"  ROUGE-1: {test_results['test_rouge1']:.4f}\")\n    print(f\"  ROUGE-2: {test_results['test_rouge2']:.4f}\")\n    print(f\"  ROUGE-L: {test_results['test_rougeL']:.4f}\")\n\n    print(\"\\n--- Generating sample predictions ---\")\n    sample_data = dataset_dict['test'].select(range(3))\n    sample_tokenized = tokenized_datasets['test'].select(range(3))\n\n    predictions = trainer.predict(sample_tokenized)\n    decoded_preds = tokenizer.batch_decode(predictions.predictions, skip_special_tokens=True)\n\n    print(\"\\nSample Predictions:\")\n    for i, (article, reference, prediction) in enumerate(zip(\n        sample_data['article'],\n        sample_data['summary'],\n        decoded_preds\n    )):\n        print(f\"\\nSample {i+1}:\")\n        print(f\"| Article   |: {article[:150]}...\")\n        print(f\"| Reference |: {reference}\")\n        print(f\"| Prediction|: {prediction.strip()}\")\n        print(\"-\" * 50)\n\n    # 🎯 SAVE THE TRAINED MODEL AND TOKENIZER\n    print(f\"\\n{'='*60}\")\n    print(\"SAVING TRAINED MODEL AND TOKENIZER\")\n    print(f\"{'='*60}\")\n    \n    try:\n        # Create save directory if it doesn't exist\n        os.makedirs(save_path, exist_ok=True)\n        \n        # Save the trained model\n        model.save_pretrained(save_path)\n        print(f\"✅ Model saved to: {save_path}\")\n        \n        # Save the tokenizer\n        tokenizer.save_pretrained(save_path)\n        print(f\"✅ Tokenizer saved to: {save_path}\")\n        \n        # Save training configuration for reference\n        config_info = {\n            'original_model': model_name,\n            'max_input_length': MAX_INPUT_LENGTH,\n            'max_target_length': MAX_TARGET_LENGTH,\n            'num_train_epochs': NUM_TRAIN_EPOCHS,\n            'train_batch_size': TRAIN_BATCH_SIZE,\n            'test_rouge1': test_results['test_rouge1'],\n            'test_rouge2': test_results['test_rouge2'],\n            'test_rougeL': test_results['test_rougeL']\n        }\n        \n        import json\n        with open(f\"{save_path}/training_config.json\", \"w\") as f:\n            json.dump(config_info, f, indent=2)\n        print(f\"✅ Training config saved to: {save_path}/training_config.json\")\n        \n        print(f\"\\n🎉 MODEL SUCCESSFULLY SAVED!\")\n        print(f\"📁 Location: {save_path}\")\n        print(f\"📋 Files saved:\")\n        print(f\"   - pytorch_model.bin (model weights)\")\n        print(f\"   - config.json (model configuration)\")\n        print(f\"   - tokenizer.json (tokenizer)\")\n        print(f\"   - tokenizer_config.json (tokenizer config)\")\n        print(f\"   - training_config.json (your training info)\")\n        \n    except Exception as e:\n        print(f\"❌ Error saving model: {str(e)}\")\n        raise e\n\n    # Clean up GPU memory\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n\n    return {\n        'model_name': model_name,\n        'save_path': save_path,\n        'rouge1': test_results['test_rouge1'],\n        'rouge2': test_results['test_rouge2'],\n        'rougeL': test_results['test_rougeL']\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T07:12:55.023140Z","iopub.execute_input":"2025-07-24T07:12:55.023712Z","iopub.status.idle":"2025-07-24T07:12:55.110742Z","shell.execute_reply.started":"2025-07-24T07:12:55.023688Z","shell.execute_reply":"2025-07-24T07:12:55.110126Z"}},"outputs":[{"name":"stdout","text":"Dataset loaded with 200 samples\nTrain set: 160 samples\nValidation set: 20 samples\nTest set: 20 samples\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"print(f\"Model: {BEST_MODEL}\")\nprint(f\"Save path: {SAVE_MODEL_PATH}\")\n\nresult = train_and_save_model(BEST_MODEL, dataset_dict, SAVE_MODEL_PATH)\n\nprint(f\"Model: {result['model_name']}\")\nprint(f\"Saved Path: {result['save_path']}\")\nprint(f\"ROUGE-1: {result['rouge1']:.4f}\")\nprint(f\"ROUGE-2: {result['rouge2']:.4f}\")\nprint(f\"ROUGE-L: {result['rougeL']:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T07:12:55.111368Z","iopub.execute_input":"2025-07-24T07:12:55.111541Z","iopub.status.idle":"2025-07-24T07:16:27.812320Z","shell.execute_reply.started":"2025-07-24T07:12:55.111527Z","shell.execute_reply":"2025-07-24T07:16:27.811633Z"}},"outputs":[{"name":"stdout","text":"Model: gaduhhartawan/indobart-base\nSave path: ./saved_indobart_model\n\n============================================================\nTraining and Saving Model: gaduhhartawan/indobart-base\n============================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"976aa1ede58d49c286081dc418929cc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f812efc9e6194c3485c49bfd0801cc8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc40617a14504f8bb014908b181b3363"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e85d075d38c546ac9cee5b18d0cec7e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10ba33fbcef942b5945cdb261a08def8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/356 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5512b0f0fb7a4e98b62ae03565179828"}},"metadata":{}},{"name":"stdout","text":"Alert: Vocab size mismatch found for gaduhhartawan/indobart-base.\n  - Model config vocab size: 50264\n  - Tokenizer vocab size:    50265\nResizing model token embeddings to match tokenizer.\n","output_type":"stream"},{"name":"stderr","text":"The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/160 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8ec637caff4448f9381a7ca3c7e251e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/20 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b964b3077b644e6ca35af588435af405"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/20 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdfc88f6bd614575b4abd29beb9262b9"}},"metadata":{}},{"name":"stdout","text":"--- Starting training ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='160' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [160/160 03:00, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.127200</td>\n      <td>2.052587</td>\n      <td>0.244004</td>\n      <td>0.079714</td>\n      <td>0.184578</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.438300</td>\n      <td>2.048216</td>\n      <td>0.277170</td>\n      <td>0.105013</td>\n      <td>0.233914</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.029300</td>\n      <td>2.221187</td>\n      <td>0.273347</td>\n      <td>0.100168</td>\n      <td>0.212518</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.762400</td>\n      <td>2.409934</td>\n      <td>0.259002</td>\n      <td>0.089648</td>\n      <td>0.212860</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n","output_type":"stream"},{"name":"stdout","text":"\n--- Evaluating on test set ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"early stopping required metric_for_best_model, but did not find eval_rougeL so early stopping is disabled\n","output_type":"stream"},{"name":"stdout","text":"\nFinal Test Results for gaduhhartawan/indobart-base:\n  ROUGE-1: 0.2635\n  ROUGE-2: 0.0839\n  ROUGE-L: 0.2162\n\n--- Generating sample predictions ---\n\nSample Predictions:\n\nSample 1:\n| Article   |: Apa yang terjadi saat manusia sekarat?.\nOrang-orang sering mengira bahwa kehidupan adalah pertempuran melawan kematian. Tetapi apakah mungkin berdama...\n| Reference |: Sejumlah orang mengatakan saat sekarat seseorang akan merasa bahagia. Apa itu benar?\n| Prediction|: Sejumlah orang sering mengira bahwa kehidupan adalah pertempuran melawan kematian dan apakah mungkin berdamai dengan kemampuan menelan tablet dan minuman selama hampir dua minggu sebelum kita meninggal.\n--------------------------------------------------\n\nSample 2:\n| Article   |: Tes darah rutin dapat deteksi kanker ovarium.\nUji coba ini akan mengubah metode deteksi tes darah Hasil uji coba ini dapat mengubah metode pemeriksaa...\n| Reference |: Tes darah rutin dapat mendeteksi 86% kanker ovarium lebih awal sebelum masa dimana perempuan dapat didiagnosa memiliki sel kanker, menurut satu uji coba.\n| Prediction|: Tes darah rutin dapat menyelamatkan lebih banyak nyawa perempuan penderita kanker ovarium yang mengidap tumor yang seringkali menyebabkan kematian karena terlambat terdeteksi.\n--------------------------------------------------\n\nSample 3:\n| Article   |: Surat Gandhi terjual miliaran rupiah.\nTandatangan Gandhi terdapat di halaman tiga surat yang terjual lebih dari satu miliar tersebut. Harga jual sura...\n| Reference |: Sebuah surat Mahatma Gandhi terjual £115.000 atau sekitar Rp1,7 miliar dalam lelang di Ludlow, Inggris.\n| Prediction|: Seorang pemimpin India menjual sebuah surat penting yang dibuat seorang mantan pejuang kemerdekaan India, Gandhi, sebagai bagian dari negosiasi rahasia yang terjual di Kecamatan Tahanan, Mahkamat, Jawa Tengah.\n--------------------------------------------------\n\n============================================================\nSAVING TRAINED MODEL AND TOKENIZER\n============================================================\n✅ Model saved to: ./saved_indobart_model\n✅ Tokenizer saved to: ./saved_indobart_model\n✅ Training config saved to: ./saved_indobart_model/training_config.json\n\n🎉 MODEL SUCCESSFULLY SAVED!\n📁 Location: ./saved_indobart_model\n📋 Files saved:\n   - pytorch_model.bin (model weights)\n   - config.json (model configuration)\n   - tokenizer.json (tokenizer)\n   - tokenizer_config.json (tokenizer config)\n   - training_config.json (your training info)\nModel: gaduhhartawan/indobart-base\nSaved Path: ./saved_indobart_model\nROUGE-1: 0.2635\nROUGE-2: 0.0839\nROUGE-L: 0.2162\n","output_type":"stream"}],"execution_count":5}]}